# ğŸ“ Assignment 14: Ethics & Explainability â€“ Credit Card Fraud Detection

## ğŸ¯ Objective

* Explain predictions of your ML model using **SHAP**.
* Understand **why a transaction is flagged as fraud or not**.
* Add an **â€œExplainabilityâ€** section to your project report.

---

## ğŸ› ï¸ Tools & Libraries

* **Python** ğŸ
* `pandas` â€“ data handling ğŸ—‚ï¸
* `joblib` â€“ load saved model & scaler ğŸ”§
* `shap` â€“ interpret ML predictions ğŸ‘ï¸
* `matplotlib` â€“ visualization ğŸ“Š

---

## ğŸ”¹ Steps Taken

1ï¸âƒ£ Load Model & Scaler

2ï¸âƒ£ Load Dataset

3ï¸âƒ£ Create SHAP Explainer

4ï¸âƒ£ Explain a Transaction

5ï¸âƒ£ Optional: Summary Plot for Multiple Transactions


## ğŸ“Š Results

* Each bar shows how much a feature contributes to **fraud probability**.
* Positive bars â†’ increase likelihood of fraud.
* Negative bars â†’ decrease likelihood of fraud.
* Summary plot highlights **most important features across multiple transactions**.

---

## ğŸ” Reflection

* SHAP helps **interpret black-box models** (MLP, Random Forest, etc.).
* Adds **ethics and transparency** to AI by showing why a model made a decision.
* Useful for **fraud investigation, audits, or compliance**.

---

## âš¡ Key Takeaways

* Always scale numeric data before explainability.
* Use **Kernel SHAP** for any model, **Tree SHAP** for tree-based models (faster).
* Explainability is essential for **trustworthy AI**.
